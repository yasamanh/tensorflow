{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pylib.tensorboardcmd import tensorboard_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_vars():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<!-- requirement: images/VAE.png -->\n",
    "<!-- requirement: pylib/__init__.py -->\n",
    "<!-- requirement: pylib/tensorboardcmd.py -->\n",
    "\n",
    "# Variational Autoencoders\n",
    "\n",
    "## Autoencoders\n",
    "\n",
    "Autoencoders are neural networks where the number of input and output neurons are the same. If our input neurons represent pixels in an image, the output of our antoencoder will ideally be the input image. Why would we want to create a model that simply reproduces our data? If we restrict the number of neurons in our hidden layers to be less than the number of input or output neurons, we force our model to learn sparse representations of the data. Therefore, autoencoders can be used for image compression and removing noise from images. \n",
    "\n",
    "![VAE](images/VAE.png)\n",
    "\n",
    "An autoencoder consists of two neural networks -- an **encoder** and **decoder**. The encoder takes in high dimensional data and generates low dimensional representations of that data. Then, the decoder takes the low dimensional representations and translates them back into the high dimensional input space. \n",
    "\n",
    "## Variational Autoencoders (VAEs)\n",
    "\n",
    "Variational Autoencoders (VAEs) differ from regular autoencoders, because they not only learn sparse representations of data but also generate new data. Consequently, VAEs are used to [create new images](https://openai.com/blog/generative-models/). For example, we can train a VAE on the MNIST dataset and have it create an image of a handwritten \"5.\" \n",
    "\n",
    "How do VAEs generate new data? They do so by making smart assumptions about the distributions of these sparse data representations, or **latent vectors**. More generally, they belong to a class of models called generative models, which learn the joint probability distribution between the input ($x$) and output (or latent vectors, $z$). We can then use this information to come up with likely $(x,z)$ pairs. For example, once we learn the distribution corresponding to the sparse representation of a handwritten \"5,\" we can sample from this distribution to form new latent vectors for \"5.\" \n",
    "\n",
    "Due to this constraint on the distributions of $z$, VAEs require an additional component in their loss function that penalizes deviations from these distributions.   \n",
    "\n",
    "In this tutorial, we will build a simple VAE to recreate images in the MNIST dataset. We will start off as usual by resetting our session, loading our data, setting our variables, and defining our weights and biases functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reset_tf()\n",
    "\n",
    "# Load Data\n",
    "data = input_data.read_data_sets('/tmp/data/', one_hot=True)\n",
    "\n",
    "# Get classes for test data\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set the path to our summary logs\n",
    "now = datetime.now()\n",
    "logs_path = now.strftime(\"%Y%m%d-%H%M%S\") + '/summaries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "batch_size = 256\n",
    "num_iterations = 400  # 1500\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Encoder and decoder\n",
    "\n",
    "As mentioned in above, VAEs make assumptions about the distribution of latent variables. Therefore, we will now consider VAEs from a probability framework. \n",
    "\n",
    "Recall **Bayes' Theorem** that tells us:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "P(z \\mid x) &=& \\frac{P(x \\mid z) \\cdot P(z)}{P(x)} \\\\\n",
    "\\\\\n",
    "\\text{posterior distribution} &=& \\frac{\\text{likelihood} \\times \\text{prior}}{\\text{marginal likelihood}}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "\n",
    "Say we have data $x$ and latent variables $z$. The encoder tries to approximate the posterior distribution $P(z \\mid x)$, or generate latent variables conditioned on the data. On the other hand, the decoder takes $z$ [sampled from $P(z \\mid x)$] and outputs parameters to the likelihood distribution $P(x \\mid z)$. These parameters are the weights and biases of the neural networks. \n",
    "\n",
    "Going back to the neural network framework, in the code below, our encoder and decoder are neural networks (of two layers each) that are mirrored images of each other. We feed the output of the encoder directly into the decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "def encoder(x, out_sizes):\n",
    "    for size in out_sizes:\n",
    "        x = tf.layers.dense(x, size, activation=tf.nn.sigmoid, use_bias=True,\n",
    "            kernel_initializer=tf.truncated_normal_initializer())\n",
    "    return x\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x, out_sizes):\n",
    "    # Reverse the sizes, skipping the smallest and adding a layer to return the original size\n",
    "    out_sizes = out_sizes[-2::-1] + [img_size_flat]\n",
    "    for size in out_sizes:\n",
    "        x = tf.layers.dense(x, size, activation=tf.nn.sigmoid, use_bias=True,\n",
    "            kernel_initializer=tf.truncated_normal_initializer())\n",
    "    return x\n",
    "\n",
    "out_sizes = [256, 128]\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(x, out_sizes)\n",
    "decoder_op = decoder(encoder_op, out_sizes)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## KL-divergence\n",
    "\n",
    "We want our network to be accurate, but we also want the latent variables to approximate the posterior distribution. The amount of information lost when approximating $P(z \\mid x)$ is called the [Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullbackâ€“Leibler_divergence), and we will use it to construct our loss function. To make our lives simple, we will choose the posterior distribution to be a unit normal and [calculate](http://allisons.org/ll/MML/KL/Normal/) the divergence accordingly. \n",
    "\n",
    "Why do we want our latent variables to approximate a certain distribution? We want them to be useful, so we impose this constraint. We can think of this as a form of  of regularization where we lose some fidelity to ensure we are capturing only important features. In other words, we want to build a model that can generate images and not just memorize them. A nice explanation of choosing latent variables can be found [here](http://kvfrans.com/variational-autoencoders-explained/).\n",
    "\n",
    "We also want to minimize the loss due to inaccurate pixel values and must therefore create a component of the loss function that penalizes these errors. This component is called `generation_loss` in the code below, and it is the squared difference between the true and regenerated pixel values in our images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "generation_loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "\n",
    "z_mean, z_var = tf.nn.moments(encoder_op, axes=[0], name='moments', keep_dims=True)\n",
    "z_stddev = tf.sqrt(z_var)\n",
    "kl_loss = 0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - 1,1)\n",
    "\n",
    "loss = tf.reduce_mean(generation_loss + kl_loss)\n",
    "tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Adam optimizer\n",
    "\n",
    "We also define an optimizer, but unlike last time, we will use the Adam Optimizer instead of the Gradient Descent Optimizer. This optimizer uses a decaying learning rate. \n",
    "\n",
    "As a reminder, we can interpret the learning rate as the size of the step we take down a gradient of our loss function. If the step size is too large, we may never get to the minimum. A large learning rate will manifest itself as noise in our loss curve that never converges to a minimum point. However, if we have a very small step size, our model may take a long time to run. Ideally, we want to take large steps at the start of the training process and small steps towards the end. The [Adam Optimizer](https://arxiv.org/pdf/1412.6980v8.pdf) changes the learning rate for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we have done in the previous model we built, we then merge our summaries and initialize and lunch the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Merge all summaries\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "#Create summary writers\n",
    "train_writer = tf.summary.FileWriter(logs_path + '/train', graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then we will train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    #Initialize\n",
    "    reset_vars()\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    step = 1\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Get a batch of training examples.\n",
    "        x_batch, y_batch = data.train.next_batch(batch_size)\n",
    "\n",
    "        # ---------------------- TRAIN -------------------------\n",
    "        # optimize model\n",
    "        sess.run(optimizer, feed_dict={x: x_batch}) \n",
    "        \n",
    "        \n",
    "        # Print status every 100 iterations.\n",
    "        if (i % display_step == 0) or (i == num_iterations - 1):\n",
    "            \n",
    "            summary, l = sess.run([merged, loss], feed_dict={x: x_batch})\n",
    "            train_writer.add_summary(summary, step)\n",
    "            \n",
    "            # Message for network evaluation\n",
    "            msg = \"Optimization Iteration: {0:>6}, Train Loss: {1:>6}\"\n",
    "            print(msg.format(i, l))\n",
    "            \n",
    "            step += 1\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimize(num_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can view and evaluate our model on TensorBoard by running the command line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Close summary writer\n",
    "train_writer.close()\n",
    "\n",
    "tensorboard_cmd(logs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally we will regenerate 10 of the MNIST images. We will display the original test images above the regenerated ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_examples = 10\n",
    "\n",
    "# Applying encode and decode over test set\n",
    "encode_decode = sess.run(decoder_op, feed_dict={x: data.test.images[:n_examples]})\n",
    "\n",
    "# Compare original images with their reconstructions\n",
    "f, a = plt.subplots(2, n_examples, figsize=(20, 4))\n",
    "for i in range(n_examples):\n",
    "    a[0][i].imshow(np.reshape(data.test.images[i], img_shape))\n",
    "    a[1][i].imshow(np.reshape(encode_decode[i], img_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exercise: The influence of the loss functions\n",
    "\n",
    "Rerun the code a couple more times, but remove one of the two loss components -- `generation_loss` and `kl_loss`. How do the results change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Copyright &copy; 2017 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
